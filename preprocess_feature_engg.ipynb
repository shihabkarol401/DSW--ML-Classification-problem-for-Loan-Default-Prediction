{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel('train_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling Missing Values...\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling Missing Values...\")\n",
    "train_data = train_data.dropna(thresh=0.5 * len(train_data), axis=1)  # Drop columns with >50% missing\n",
    "\n",
    "numerical_cols = ['cibil_score', 'total_no_of_acc', 'annual_inc', 'int_rate', \n",
    "                  'loan_amnt', 'installment', 'account_bal', 'emp_length']\n",
    "categorical_cols = ['sub_grade', 'term', 'home_ownership', 'purpose', \n",
    "                    'application_type', 'verification_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute numerical and categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values handled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating the Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    upper_limit = train_data[col].quantile(0.99)\n",
    "    lower_limit = train_data[col].quantile(0.01)\n",
    "    train_data[col] = np.clip(train_data[col], lower_limit, upper_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    label_encoders[col] = le  # Save encoder for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['transaction_date'] = pd.to_datetime(train_data['transaction_date'])\n",
    "train_data['year'] = train_data['transaction_date'].dt.year\n",
    "train_data['month'] = train_data['transaction_date'].dt.month\n",
    "train_data['day'] = train_data['transaction_date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Numerical Features...\n",
      "Numerical features scaled.\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaling Numerical Features...\")\n",
    "scaler = StandardScaler()\n",
    "train_data[numerical_cols] = scaler.fit_transform(train_data[numerical_cols])\n",
    "print(\"Numerical features scaled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lagged_account_bal'] = train_data['account_bal'].shift(1).fillna(0)\n",
    "train_data['lagged_installment'] = train_data['installment'].shift(1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['rolling_mean_account_bal'] = train_data['account_bal'].rolling(window=3).mean().fillna(train_data['account_bal'].mean())\n",
    "train_data['rolling_std_account_bal'] = train_data['account_bal'].rolling(window=3).std().fillna(train_data['account_bal'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cibil_int_rate'] = train_data['cibil_score'] * train_data['int_rate']\n",
    "train_data['income_loan_ratio'] = train_data['annual_inc'] / (train_data['loan_amnt'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bining Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cibil_score_bin'] = pd.cut(train_data['cibil_score'], bins=[0, 600, 700, 800, 900], labels=['Poor', 'Fair', 'Good', 'Excellent'])\n",
    "train_data['int_rate_bin'] = pd.cut(train_data['int_rate'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target based Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    target_mean = train_data.groupby(col)['loan_status'].mean()\n",
    "    train_data[f'{col}_target_enc'] = train_data[col].map(target_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Time-Since Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = train_data['transaction_date'].max()\n",
    "train_data['days_since_transaction'] = (current_date - train_data['transaction_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Aggregated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['avg_account_bal_by_grade'] = train_data.groupby('sub_grade')['account_bal'].transform('mean')\n",
    "train_data['total_loans_by_purpose'] = train_data.groupby('purpose')['loan_amnt'].transform('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and Feature Engineering complete. Data saved to 'preprocessed_train_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "train_data.to_csv('preprocessed_train_data.csv', index=False)\n",
    "print(\"Preprocessing and Feature Engineering complete. Data saved to 'preprocessed_train_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preprocessing on Test Data...\n",
      "Handling Missing Values in Test Data...\n",
      "Missing values handled in Test Data.\n",
      "Treating Outliers in Test Data...\n",
      "Outliers treated in Test Data.\n",
      "Encoding Categorical Variables in Test Data...\n",
      "Categorical variables encoded in Test Data.\n",
      "Creating Time-Based Features in Test Data...\n",
      "Time-based features created in Test Data.\n",
      "Scaling Numerical Features in Test Data...\n",
      "Numerical features scaled in Test Data.\n",
      "Starting Feature Engineering on Test Data...\n",
      "Feature Engineering complete on Test Data.\n",
      "Preprocessing and Feature Engineering on Test Data complete. Data saved to 'preprocessed_test_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "test_data = pd.read_excel('test_data.xlsx')  # Replace with your test file path\n",
    "\n",
    "print(\"Starting Preprocessing on Test Data...\")\n",
    "\n",
    "\n",
    "print(\"Handling Missing Values in Test Data...\")\n",
    "test_data = test_data.dropna(thresh=0.5 * len(test_data), axis=1)  # Drop columns with >50% missing\n",
    "\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].fillna(train_data[col].median())\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].fillna(train_data[col].mode()[0])\n",
    "\n",
    "print(\"Missing values handled in Test Data.\")\n",
    "\n",
    "\n",
    "print(\"Treating Outliers in Test Data...\")\n",
    "for col in numerical_cols:\n",
    "    if col in test_data.columns:\n",
    "        upper_limit = train_data[col].quantile(0.99)\n",
    "        lower_limit = train_data[col].quantile(0.01)\n",
    "        test_data[col] = np.clip(test_data[col], lower_limit, upper_limit)\n",
    "print(\"Outliers treated in Test Data.\")\n",
    "\n",
    "\n",
    "print(\"Encoding Categorical Variables in Test Data...\")\n",
    "for col, le in label_encoders.items():\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = le.transform(test_data[col])\n",
    "\n",
    "print(\"Categorical variables encoded in Test Data.\")\n",
    "\n",
    "\n",
    "print(\"Creating Time-Based Features in Test Data...\")\n",
    "test_data['transaction_date'] = pd.to_datetime(test_data['transaction_date'])\n",
    "test_data['year'] = test_data['transaction_date'].dt.year\n",
    "test_data['month'] = test_data['transaction_date'].dt.month\n",
    "test_data['day'] = test_data['transaction_date'].dt.day\n",
    "print(\"Time-based features created in Test Data.\")\n",
    "\n",
    "\n",
    "print(\"Scaling Numerical Features in Test Data...\")\n",
    "test_data[numerical_cols] = scaler.transform(test_data[numerical_cols])\n",
    "print(\"Numerical features scaled in Test Data.\")\n",
    "\n",
    "\n",
    "print(\"Starting Feature Engineering on Test Data...\")\n",
    "\n",
    "\n",
    "test_data['lagged_account_bal'] = test_data['account_bal'].shift(1).fillna(0)\n",
    "test_data['lagged_installment'] = test_data['installment'].shift(1).fillna(0)\n",
    "\n",
    "\n",
    "test_data['rolling_mean_account_bal'] = test_data['account_bal'].rolling(window=3).mean().fillna(test_data['account_bal'].mean())\n",
    "test_data['rolling_std_account_bal'] = test_data['account_bal'].rolling(window=3).std().fillna(test_data['account_bal'].std())\n",
    "\n",
    "\n",
    "test_data['cibil_int_rate'] = test_data['cibil_score'] * test_data['int_rate']\n",
    "test_data['income_loan_ratio'] = test_data['annual_inc'] / (test_data['loan_amnt'] + 1)\n",
    "\n",
    "\n",
    "test_data['cibil_score_bin'] = pd.cut(test_data['cibil_score'], bins=[0, 600, 700, 800, 900], labels=['Poor', 'Fair', 'Good', 'Excellent'])\n",
    "test_data['int_rate_bin'] = pd.cut(test_data['int_rate'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in test_data.columns:\n",
    "        target_mean = train_data.groupby(col)['loan_status'].mean()\n",
    "        test_data[f'{col}_target_enc'] = test_data[col].map(target_mean)\n",
    "\n",
    "\n",
    "current_date = train_data['transaction_date'].max()\n",
    "test_data['days_since_transaction'] = (current_date - test_data['transaction_date']).dt.days\n",
    "\n",
    "\n",
    "if 'sub_grade' in test_data.columns:\n",
    "    test_data['avg_account_bal_by_grade'] = test_data.groupby('sub_grade')['account_bal'].transform('mean')\n",
    "if 'purpose' in test_data.columns:\n",
    "    test_data['total_loans_by_purpose'] = test_data.groupby('purpose')['loan_amnt'].transform('sum')\n",
    "\n",
    "print(\"Feature Engineering complete on Test Data.\")\n",
    "\n",
    "# Save Preprocessed Test Data\n",
    "test_data.to_csv('preprocessed_test_data.csv', index=False)\n",
    "print(\"Preprocessing and Feature Engineering on Test Data complete. Data saved to 'preprocessed_test_data.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
